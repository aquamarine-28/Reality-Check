# Reality Check
 _Reality Check_, an instance segementation detection model.


## Problem and Objective
With the latest innovations in deep fake technologies and video production, it has become more challenging to distinguish between real and AI-generated images and videos. As a consequence, malicious and harmful media can now be created and disseminated online with relative ease, which can cause significant harm to the mental health, reputation, and overall character of an individual. To address this issue, we created "Reality Check," an image detection model that utilizes instances of AI-manipulation to accurately analyze and determine authentic and deepfaked images, instead of relying solely on classification data.


## Methodologies


## Key Results
By our tests, our model can perform segmentation, analysis, and classification of images in as little as 2.0ms, with a 75-80% accuracy.

### Post Training Results

## Data Sources
Dataset - https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images

## Technologies Used
- Python
- Google Colaboratory
- Roboflow
- OpenCV
- Flask

## Authors
This project was developed by: 
- Mark-Anthony Delva ([ _@MrkAnthony_ ](https://github.com/MrkAnthony))
- Nmesoma Duru ([ _@nmesosphere_ ](https://github.com/nmesosphere))
- Micheal Johnson ([ _@SolaMike_ ](https://github.com/SolaMike))

